---
title: "Assignment 3"
author: "Emanuele Coradin"
date: "2024-05-13"
output: 
  read_document: rmdformats::readthedown
  html_document:
    number_sections: true
    theme: spacelab
  pdf_document:
    number_sections: true
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

color_vector <- c("#CC0000",   # Dark red
                  "#CC79A7",   # Muted purple
                  "#D55E00",   # Vermilion
                  "#009E73",   # Bluish green
                  "#56B4E9",   # Sky blue
                  '#000046',   # Deep Blue
                  "#DB1E60",   # Pinkish-red
                  "#E69F00")   # Yellow-orange

```

```{r, message=FALSE, echo=FALSE}
library(dplyr)
library(ggplot2)
library(reshape2)
```

# Exercise 1: Bayesian Inference for Poisson model

The number of particles emitted by a radioactive source during a fixed interval of time $(\Delta t = 10 s)$ follows a Poisson distribution on the parameter $\mu$. The number of particles observed during consecutive time intervals is: 4, 1, 3, 1, 5 and 3.

    1.1. Assuming a positive uniform prior distribution for the parameter $\mu$ :

```         
* determine and draw the posterior distribution for µ, given the data 

* evaluate mean, median and variance, both analytically and numerically in R;
```

    1.2. assuming a Gamma prior such that the expected value is $\mu = 3$ with a standard deviation $\sigma = 1$,

```         
* determine and draw the posterior distribution for µ, given the data;

* evaluate mean, median and variance, both analytically and numerically in R. 
```

    1.3. evaluate a $95\%$ credibility interval for the results obtained with different priors. Compare the result with that obtained using a normal approximation for the posterior distribution, with the same mean and standard deviation.

```{r }
#------------- Useful functions -------------
mean_pdf   <- function(f, lower, upper){integrate(function(x) x*f(x), lower, upper)$value}
std_pdf <- function(f, lower, upper) {
  mu <- mean_pdf(f, lower, upper)
  sqrt(integrate(function(x) (x - mu)^2 * f(x), lower, upper)$value / integrate(f, lower, upper)$value)
}
cumulative <- function(f, lower, X){integrate(f, lower, X)$value}
inverse_cumulative <- function(f, p, lower, upper){uniroot(function(x) cumulative(f, lower, x)-p, c(lower, upper))$root}

#inference functions
binom_likelihood <- function(prob, ...) sapply(prob, function(P)  prod(dbinom(prob=P, ...)))
pois_likelihood  <- function(mu, ...)   sapply(mu,   function(MU) prod(dpois (lambda = MU, ...)))

posterior <- function(parameter, prior, likelihood, lower, upper, ...) {
  unnormalized <- function(x) likelihood(x, ...)*prior(x)
  norm_factor  <- integrate(unnormalized, lower = lower, upper = upper)$value
  unnormalized(parameter)/norm_factor
}

```

```{r 1.1}
#coding the data from the observations
observed_particles <- c(4, 1, 3, 1, 5, 3)
particles_mean <- observed_particles %>% mean
particles_std  <- observed_particles %>% sd

writeLines(sprintf(
  'The observed number of particles in a fixed time interval of 10s is on average %.1f, with a standard deviation of %.1f',
  particles_mean, particles_std
))

#------------------------------------------------
#------------ POSITIVE UNIFORM PRIOR ------------
#------------------------------------------------

#boundaries for the uniform prior
mu_lim <- c(1, 20)
p_mu <- 1./(mu_lim[2]-mu_lim[1])


#definition of prior and calculation of the posterior
uniform_prior     <- function(mu) sapply(mu, function(x) ifelse(x > mu_lim[1] && x < mu_lim[2], p_mu, 0))
uniform_posterior <- function(mu) posterior(mu, uniform_prior, pois_likelihood, lower=mu_lim[1], upper=mu_lim[2], x=observed_particles)

#compute the 95% credibility interval
uniform_95_interval <- sapply(c(0.025, 0.975), function(P) inverse_cumulative(uniform_posterior, p = P, lower = mu_lim[1], upper = mu_lim[2]))

#-------------- Plot the posterior --------------

curve(uniform_posterior, from = 0, to = mu_lim[2], xlab = expression(mu), ylab = 'Posterior', col=color_vector[1], main='Activity using a uniform prior', xlim = c(0,8), lwd=2, n = 500) 

grid()

x_plot <- seq(from=uniform_95_interval[1], to=uniform_95_interval[2], length.out=500)
y_plot <- c(0, uniform_posterior(x_plot), 0)
x_plot <- c(uniform_95_interval[1], x_plot, uniform_95_interval[2])
polygon(x_plot, y_plot, col = adjustcolor(color_vector[7], alpha.f = 0.25),border = NA)

abline(v = mean(observed_particles), col = color_vector[6], lwd=2, lty='dashed')


#--------- Computing mean, std, median ----------

mean_uniform   <- mean_pdf(uniform_posterior, lower = mu_lim[1], upper=mu_lim[2])
std_uniform    <- std_pdf (uniform_posterior, lower = mu_lim[1], upper=mu_lim[2])
median_uniform <- inverse_cumulative(uniform_posterior, 0.5, mu_lim[1], mu_lim[2])

writeLines(sprintf(
  '
  The mean of the posterior is: %.2f ;
  The standard deviation is: %.2f ;
  The median is : %.2f .
  ', mean_uniform, std_uniform, median_uniform)
)
```

```{r 1.2}

#------------------------------------------------
#------------------ GAMMA PRIOR -----------------
#------------------------------------------------

mean_prior  <- 3
sigma_prior <- 1

#calculate the parameters from the hypothesis
shape <- (mean_prior / sigma_prior)^2 
rate <- mean_prior/(sigma_prior^2)

#definition of prior and calculation of the posterior and 95% credibility interval
gamma_prior       <- function(mu) dgamma(mu, shape = shape, rate = rate)
gamma_posterior   <- function(mu) posterior(mu, gamma_prior, pois_likelihood, lower=0, upper=Inf, x=observed_particles)
gamma_95_interval <- sapply(c(0.025, 0.975), function(P) inverse_cumulative(gamma_posterior, p = P, lower = 0, upper = 10))

#-------------- Plot the posterior --------------

curve(gamma_posterior, from = 0, to = 11, xlab = expression(mu), ylab = 'Posterior', col=color_vector[1], main='Activity using a gamma prior', xlim = c(0,8), lwd=2, n = 500) 
grid()

x_plot <- seq(from=gamma_95_interval[1], to=gamma_95_interval[2], length.out=100)
y_plot <- c(0, gamma_posterior(x_plot), 0)
x_plot <- c(gamma_95_interval[1], x_plot, gamma_95_interval[2])
polygon(x_plot, y_plot, col = adjustcolor(color_vector[7], alpha.f = 0.25),border = NA)

abline(v = mean(observed_particles), col = color_vector[6], lwd=2, lty='dashed')


#--------- Computing mean, std, median ----------

mean_gamma   <- mean_pdf(gamma_posterior, lower = 0, upper=Inf)
std_gamma    <- std_pdf (gamma_posterior, lower = 0, upper=Inf)
median_gamma <- inverse_cumulative(gamma_posterior, 0.5, 0, 20)

writeLines(sprintf(
  '
  The mean of the posterior is: %.2f ;
  The standard deviation is: %.2f ;
  The median is : %.2f .
  ', mean_gamma, std_gamma, median_gamma)
)
```

# Exercise 2: Efficiency using Bayesian approach

A researcher A wants to evaluate the efficiency of detector 2 (Det2). For this purpose, he sets up the apparatus shown in the figure 1, where Det2 is sandwiched between Det1 and Det3. Let n be the number of signals recorded simultaneously by Det1 and Det3, and r be those also recorded by Det2, researcher A obtains n = 500 and r = 312. Assuming a binomial model where n is the number of trials and r is the number of success out of n trials,

    2.1. Evaluate the mean and the variance using a Bayesian approach under the hypothesis of:

        * uniform prior ∼ U(0, 1) 

        * Jeffrey’s prior ∼ Beta(1/2, 1/2) 
  
    2.2. Plot the posterior distributions for both cases 
```{r 2.1 2.2}
n = 500
r = 312

#---------- CALCULATIONS ---------- 

uniform_prior     <- function(eff) sapply(eff, function(x) ifelse(x>=0 && x<=1, 1, 0))
uniform_posterior <- function(eff) posterior(eff, uniform_prior, binom_likelihood, lower=0, upper=1, size=n, x=r)
jeffrey_prior     <- function(eff) dbeta(eff, 0.5, 0.5)
jeffrey_posterior <- function(eff) posterior(eff, jeffrey_prior, binom_likelihood, lower=0, upper=1, size=n, x=r)

mean_uniform <- mean_pdf(uniform_posterior, lower = 0, upper=1)
std_uniform  <- std_pdf (uniform_posterior, lower = 0, upper=1)
mean_jeffrey <- mean_pdf(jeffrey_posterior, lower = 0, upper=1)
std_jeffrey  <- std_pdf (jeffrey_posterior, lower = 0, upper=1)

#-------------- PLOT -------------- 

curve(uniform_posterior, from = 0, to = 1, xlab = expression(Efficiency), ylab = 'Posterior', col=color_vector[1], main='Researcher A', xlim = c(.5,.75), lwd=2, n = 500) 
curve(jeffrey_posterior, from = 0, to = 1, xlab = expression(Efficiency), ylab = 'Posterior', col=color_vector[6], lty=2, add=TRUE, lwd=2, n = 500) 
grid()

legend("topright", legend = c("Uniform Posterior", "Jeffrey Posterior"), col = c(color_vector[1], color_vector[6]), lty = c(1, 2))

#------------ OUTPUT -------------- 

writeLines(sprintf(
"
Using a uniform prior the posterior has   mean %.3f with standard deviation %.2f .
Using a Jeffrey's prior the posterior has mean %.3f with standard deviation %.2f .
", mean_uniform, std_uniform, mean_jeffrey, std_jeffrey))

```

Taking into account that the same detector has been studied by researcher B, who has performed only n = 10 measurements and has obtained r = 10 signals.

    2.3. Evaluate the mean, the variance and the posterior distribution using a uniform prior with the results of researcher B.

```{r 2.3}
n = 10
r = 10

#---------- CALCULATIONS ---------- 

B.uniform_prior     <-function(eff) sapply(eff, function(x) ifelse(x>=0 && x<=1, 1, 0))
B.uniform_posterior <- function(eff) posterior(eff, B.uniform_prior, binom_likelihood, lower=0, upper=1, size=n, x=r)
B.jeffrey_prior     <- function(eff) dbeta(eff, 0.5, 0.5)
B.jeffrey_posterior <- function(eff) posterior(eff, B.jeffrey_prior, binom_likelihood, lower=0, upper=1, size=n, x=r)

B.mean_uniform <- mean_pdf(B.uniform_posterior, lower = 0, upper=1)
B.std_uniform  <- std_pdf (B.uniform_posterior, lower = 0, upper=1)
B.mean_jeffrey <- mean_pdf(B.jeffrey_posterior, lower = 0, upper=1)
B.std_jeffrey  <- std_pdf (B.jeffrey_posterior, lower = 0, upper=1)

 #-------------- PLOT -------------- 

curve(B.jeffrey_posterior, from = 0, to = 1, xlab = expression(Efficiency), ylab = 'Posterior', col=color_vector[6], main='Researcher B', lwd=2, n = 500, xlim=c(0.4, 1)) 
curve(B.uniform_posterior, from = 0, to = 1, xlab = expression(Efficiency), ylab = 'Posterior', col=color_vector[1],  add=TRUE, lwd=2, n = 500)
grid()

legend("topleft", legend = c("Uniform Posterior", "Jeffrey Posterior"), col = c(color_vector[1], color_vector[6]), lty = 1)

#------------ OUTPUT -------------- 

writeLines(sprintf(
"
Using a uniform prior the posterior has   mean %.3f with standard deviation %.2f .
Using a Jeffrey's prior the posterior has mean %.3f with standard deviation %.2f .
", B.mean_uniform, B.std_uniform, B.mean_jeffrey, B.std_jeffrey))
```

    2.4. Repeat the computation of points 2.1 and 2.2 with the data of researcher A using as a prior the posterior obtained from point 2.3.

```{r 2.4}
n = 500
r = 312

#---------- CALCULATIONS ----------

A.uniform_B_posterior <- function(eff) posterior(eff, B.uniform_posterior, binom_likelihood, lower=0, upper=1, size=n, x=r)
A.jeffrey_B_posterior <- function(eff) posterior(eff, B.jeffrey_posterior, binom_likelihood, lower=0, upper=1, size=n, x=r)

A.mean_uniform_B <- mean_pdf(A.uniform_B_posterior, lower = 0, upper=1)
A.std_uniform_B  <- std_pdf (A.uniform_B_posterior, lower = 0, upper=1)
A.mean_jeffrey_B <- mean_pdf(A.jeffrey_B_posterior, lower = 0, upper=1)
A.std_jeffrey_B  <- std_pdf (A.jeffrey_B_posterior, lower = 0, upper=1)

#-------------- PLOT -------------- 

curve(A.uniform_B_posterior, from = 0, to = 1, xlab = expression(Efficiency), ylab = 'Posterior', col=color_vector[1], main="Researcher A with Researcher's B prior", xlim=c(0.5, 0.75), lwd=2, n = 500) 
curve(A.jeffrey_B_posterior, from = 0, to = 1, xlab = expression(Efficiency), ylab = 'Posterior', col=color_vector[6], lty='dashed', main=' ', add=TRUE, lwd=2, n = 500) 
grid()

legend("topleft", legend = c("Posterior with B's uniform prior", "Posterior with B's Jeffrey prior"), col = c(color_vector[1], color_vector[6]), lty = c(1, 6))

#------------ OUTPUT -------------- 

writeLines(sprintf(
"
Using the uniform posterior of B as prior, the posterior for A has  mean %.3f with standard deviation %.2f .
Using the Jeffrey's posteriorof B as prior, the posterior for A has mean %.3f with standard deviation %.2f .
", A.mean_uniform_B, A.std_uniform_B, A.mean_jeffrey_B, A.std_jeffrey_B))

```

    2.5 [Optional] Compute $95\%$ credible interval using the posterior of the previous point 2.4.

```{r 2.5}

```

# Exercise 3 - Bayesian Inference for Binomial model

A coin is flipped n = 30 times with the following outcomes: T, T, T, T, T, H, T, T, H, H, T, T, H, H, H, T, H, T, H, T, H, H, T, H, T, H, T, H, H, H

    3.1. Assuming a flat prior, and a beta prior, plot the likelihood, prior and posterior distributions for the data set.

    3.2. Evaluate the most probable value for the coin probability p and, integrating the posterior probability distribution, give an estimate for a $95\%$ credibility interval.

    3.3. Repeat the same analysis assuming a sequential analysis of the data. Show how the most probable value and the credibility interval change as a function of the number of coin tosses (i.e. from 1 to 30).

    3.4. Do you get a different result, by analyzing the data sequentially with respect to a one-step analysis (i.e. considering all the data as a whole) ?

```{r 3}
N <- 30
coin_outcomes <- c(1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0)
alpha <- 10 ; beta <- 10;
tails = coin_outcomes |> sum()

#-------------------------- COMPUTATION ----------------------

uniform_prior     <- function(p) sapply(p, function(X) ifelse(X >= 0 && X <=1, 1, 0))
uniform_posterior <- function(p) posterior(p, uniform_prior, binom_likelihood, lower=0, upper=1, size=N, x=tails)
beta_prior        <- function(x) dbeta(x, shape1 = alpha, shape2 = beta)
beta_posterior    <- function(p) posterior(p, beta_prior, binom_likelihood, lower=0, upper=1, size=N, x=tails)

uniform_max <- optimize(uniform_posterior, c(0,1), maximum = TRUE)
beta_max    <- optimize(beta_posterior,    c(0,1), maximum = TRUE)

uniform_95_interval <- sapply(c(0.025, 0.975), function(P) inverse_cumulative(uniform_posterior, p = P, lower = 0, upper = 1))
beta_95_interval    <- sapply(c(0.025, 0.975), function(P) inverse_cumulative(beta_posterior, p = P, lower = 0, upper = 1))

#---------------------------- PLOT ---------------------------

curve(uniform_prior, from = 0, to = 1, xlab = "P", ylab = 'Probability density', col=color_vector[4], main="Coin probability inference", xlim = c(0,1), ylim=c(0,6), lwd=2) 
curve(beta_prior, from = 0, to = 1, col=color_vector[3], add=TRUE, lwd=2)

curve(uniform_posterior, from = 0, to = 1, col=color_vector[1], lty='dashed', add=TRUE, lwd=2) 
curve(beta_posterior, from = 0, to = 1, col=color_vector[5], lty='dashed', add=TRUE, lwd=2) 

uniform_x_plot <- seq(from=uniform_95_interval[1], to=uniform_95_interval[2], length.out=100)
uniform_y_plot <- c(0, uniform_posterior(uniform_x_plot), 0)
uniform_x_plot <- c(uniform_95_interval[1], uniform_x_plot, uniform_95_interval[2])

beta_x_plot <- seq(from=beta_95_interval[1], to=beta_95_interval[2], length.out=100)
beta_y_plot <- c(0, beta_posterior(beta_x_plot), 0)
beta_x_plot <- c(beta_95_interval[1], beta_x_plot, beta_95_interval[2])

polygon(uniform_x_plot, uniform_y_plot, col = adjustcolor(color_vector[1], alpha.f = 0.25),border = NA)
polygon(beta_x_plot, beta_y_plot, col = adjustcolor(color_vector[5], alpha.f = 0.25),border = NA)

grid()

legend("topleft", legend = c("Uniform Prior", "Beta Prior", "Uniform Posterior", "Beta Posterior"), col = c(color_vector[4], color_vector[3], color_vector[1], color_vector[5]), lty = c(1, 1, 2, 2))

#-------------------------- OUTPUT ---------------------------

writeLines(sprintf(
  '
  - Assuming a uniform prior, the most probable value for p is %.3f
  - The 95%% credibility interval is [ %.2f , %.2f ]
  
  - Assuming a beta(10,10) prior, the most probable value is %.3f
  - The 95%% credibility interval is [ %.2f , %.2f ]
  ', uniform_max$maximum, uniform_95_interval[1], uniform_95_interval[2], beta_max$maximum, beta_95_interval[1], beta_95_interval[2]
  )
)
```

```{r 3.3}
#using the sequential approach
coin_outcomes <- c(1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0)

N <- seq_along(coin_outcomes)
#calculate the partial outcomes after each single toss
partial_results <- sapply(N, function(i) coin_outcomes[1:i])
tails <- lapply(partial_results, function(x) sum(x))

#-------------------------- COMPUTATION ----------------------

alpha <- 10 ; beta <- 10;
uniform_prior <- function(p) sapply(p, function(X) ifelse(X >= 0 && X <=1, 1, 0))
beta_prior    <- function(x) dbeta(x, shape1 = alpha, shape2 = beta)

# define two general functions to compute the posterior at each step 
uniform_posterior <- function(p, size, x) posterior(p, uniform_prior, binom_likelihood, lower=0, upper=1, size=size, x=x)
beta_posterior <- function(p, size, x) posterior(p, beta_prior, binom_likelihood, lower=0, upper=1, size=size, x=x)

# apply them using mapply over N and tails lists
uniform_posterior_history <- function(p) {
  mapply(function(size, x) {
    function(p) uniform_posterior(p, size, x)
  }, size = N, x = tails)
}

beta_posterior_history <- function(p) {
  mapply(function(size, x) {
    function(p) beta_posterior(p, size, x)
  }, size = N, x = tails)
}

#compute the maximum for each step
uniform_max_history <- lapply(uniform_posterior_history(), 
                              function(func) optimize(func, c(0, 1), maximum = TRUE)$maximum)

beta_max_history <- lapply(beta_posterior_history(), 
                           function(func) optimize(func, c(0, 1), maximum = TRUE)$maximum)

#compute the 95% credibility interval for each step
calculate_95_interval <- function(posterior) sapply(c(0.025, 0.975), function(P) inverse_cumulative(posterior, p = P, lower = 0, upper = 1))

#save the length of the credibility intervals
uniform_interval_history <- lapply(uniform_posterior_history(), calculate_95_interval) |>
  (\(my_list) sapply(my_list, function(x) x[2] - x[1]))()
beta_interval_history <- lapply(beta_posterior_history(), calculate_95_interval) |>
  (\(my_list) sapply(my_list, function(x) x[2] - x[1]))()


#---------------------------- PLOT ---------------------------

plot(N, uniform_max_history, type = "l", col = color_vector[1], lwd = 2, ylim = c(0, 1),
     xlab = "N", ylab = "MAP Estimate", main = "MAP Estimates as a function of N")
lines(N, beta_max_history, col = color_vector[6], lwd = 2)

lines(N, uniform_interval_history, col = color_vector[1], lwd = 2, lty=2)
lines(N, beta_interval_history, col = color_vector[6], lwd = 2, lty=2)

legend("topright", legend = c("Uniform Prior", "Beta(10, 10) Prior", "Uniform CI", "Beta CI"), col = c(color_vector[1], color_vector[6], color_vector[1], color_vector[6]), lty = c(1,1,2,2), lwd=2)

points(N, uniform_max_history, col = color_vector[1], pch = 16)
points(N, beta_max_history, col = color_vector[6], pch = 16)

grid()

```

# Exercise 4 - Poll

A couple of days before an election in which four parties (A,B,C,D) compete, a poll is taken using a sample of 200 voters who express the following preferences 57, 31, 45 and 67 for, respectively, parties A,B,C and D. Using a Bayesian approach, for all parties:

    4.1. Calculate the expected percentage of votes and a 68% credibility interval by assuming as prior 
      
      – a uniform prior 
      
      – a prior constructed from the results obtained from another poll conducted the previous week on a sample of 100 voters who expressed the following preferences 32,14,26,28 for, respectively, parties A,B,C and D.
    
    4.2. Sample size to obtain a margin of error less or equal than $\pm 3\%$ for each party

## Explanation

The underlying distribution in this case is a Multinomial with 4 possible outcomes. 
The conjugate prior for a multinomial likelihood is a Dirichlet function. In particular, when $\vec{\alpha}= \vec{1}$ the Dirichlet function reduces to a uniform one.

```{r }
# Given data
N_poll <- 100
data_poll <- c(32, 14, 26, 28)

N <- 200
data <- c(57, 31, 45, 67)
labels <- c("A", "B", "C", "D")

#-------------------------------------------------------------
#-------------------------- COMPUTATION ----------------------
#-------------------------------------------------------------

# Priors
alpha_uniform_prior <- c(1., 1., 1., 1.)
alpha_poll_prior <- data_poll

# Posterior parameters
alpha_uniform_posterior <- alpha_uniform_prior + data
alpha_poll_posterior <- alpha_poll_prior + data

# Posterior means and standard deviations
uniform_alpha_0 <- sum(alpha_uniform_posterior)

uniform_means <- alpha_uniform_posterior / uniform_alpha_0
uniform_std <- sqrt((uniform_means * (1 - uniform_means)) / (uniform_alpha_0 + 1))

poll_alpha_0 <- sum(alpha_poll_posterior)

poll_means <- alpha_poll_posterior /poll_alpha_0
poll_std <- sqrt((poll_means * (1 - poll_means)) / (poll_alpha_0 + 1))

# Posterior credibility intervals
uniform_68_interval <- sapply(alpha_uniform_posterior , function(alpha_i) qbeta(c(.16, .84), shape1=alpha_i, shape2 = uniform_alpha_0 - alpha_i))

poll_68_interval <- sapply(alpha_poll_posterior , function(alpha_i) qbeta(c(.16, .84), shape1=alpha_i, shape2 = poll_alpha_0 - alpha_i))

#-------------------------------------------------------------
#---------------------------- OUTPUT -------------------------
#-------------------------------------------------------------

# Output results
output <- sprintf(
  "
  - Assuming a uniform prior, the most probable values for p are [ %.3f , %.3f , %.3f , %.3f ]
  - The standard deviations are [ %.3f , %.3f , %.3f , %.3f ]
  - The 68%% credibility intervals are [ %.2f-%.2f , %.2f-%.2f , %.2f-%.2f , %.2f-%.2f ]
  
  - Assuming the poll's prior, the most probable values are [ %.3f , %.3f , %.3f , %.3f ]
  - The standard deviations are [ %.3f , %.3f , %.3f , %.3f ]
  - The 68%% credibility intervals are [ %.2f-%.2f , %.2f-%.2f , %.2f-%.2f , %.2f-%.2f ]
  ", 
  uniform_means[1], uniform_means[2], uniform_means[3], uniform_means[4],
  uniform_std[1], uniform_std[2], uniform_std[3], uniform_std[4],
  uniform_68_interval[1,1], uniform_68_interval[2,1], uniform_68_interval[1,2], uniform_68_interval[2,2],
  uniform_68_interval[1,3], uniform_68_interval[2,3], uniform_68_interval[1,4], uniform_68_interval[2,4],
  
  poll_means[1], poll_means[2], poll_means[3], poll_means[4],
  poll_std[1], poll_std[2], poll_std[3], poll_std[4],
  poll_68_interval[1,1], poll_68_interval[2,1], poll_68_interval[1,2], poll_68_interval[2,2],
  poll_68_interval[1,3], poll_68_interval[2,3], poll_68_interval[1,4], poll_68_interval[2,4]
)

cat(output)

#-------------------------------------------------------------
#----------------------------- PLOTS -------------------------
#-------------------------------------------------------------

# Data for plotting
data_plot <- data.frame(
  Label = rep(labels, 2),
  Mean = c(uniform_means, poll_means),
  Std = c(uniform_std, poll_std),
  Prior = rep(c("Uniform", "Poll-based"), each = length(labels))
)

# Melt the dataframe for ggplot2
data_melt <- melt(data_plot, id.vars = c("Label", "Prior"))

# Plotting
ggplot(data_melt, aes(x = Label, y = value, fill = Prior)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ variable, scales = "free_y", ncol = 1) +
  labs(title = "Posterior Distributions",
       y = "Value",
       x = "Labels") +
  theme_minimal() +
  scale_fill_manual(values = c("Uniform" = "blue", "Poll-based" = "green"))

# Prepare data for ggplot2
df_means <- data.frame(
  Label = rep(labels, 2),
  Mean = c(uniform_means, poll_means),
  Lower = c(uniform_68_interval[1,], poll_68_interval[1,]),
  Upper = c(uniform_68_interval[2,], poll_68_interval[2,]),
  Prior = rep(c("Uniform Prior", "Poll-based Prior"), each = length(labels))
)

df_std <- data.frame(
  Label = rep(labels, 2),
  Std = c(uniform_std, poll_std),
  Prior = rep(c("Uniform Prior", "Poll-based Prior"), each = length(labels))
)

# Plot means with credibility intervals
ggplot(df_means, aes(x = Label, y = Mean, fill = Prior)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.7), width = 0.2) +
  labs(title = "Posterior Means with 68% Credibility Intervals",
       y = "Mean",
       x = "Labels") +
  theme_minimal() +
  scale_fill_manual(values = c("Uniform Prior" = "blue", "Poll-based Prior" = "green"))

# Plot standard deviations
ggplot(df_std, aes(x = Label, y = Std, fill = Prior)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  labs(title = "Posterior Standard Deviations",
       y = "Standard Deviation",
       x = "Labels") +
  theme_minimal() +
  scale_fill_manual(values = c("Uniform Prior" = "blue", "Poll-based Prior" = "green"))
```